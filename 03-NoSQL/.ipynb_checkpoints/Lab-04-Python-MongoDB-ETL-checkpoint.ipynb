{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b0fd2a7",
   "metadata": {},
   "source": [
    "## Using Python to Integrate MongoDB Data into an ETL Process\n",
    "Modern Data Warehousing and Analytics solutions frequently use languages like Python or Scala to extract data from numerous sources, including relational database management systems, NoSQL database systems, real-time streaming endpoints and Data Lakes. These languages can then be used to perform many types of transformation before then loading the data into a variety of destinations including file systems and data warehouses. This data can then be consumed by data scientists or business analysts.\n",
    "\n",
    "In this lab you will build upon the **Northwind_DW2** dimensional database from Lab 3; however, you will be integrating new data sourced from an instance of MongoDB. The new data will be concerned with new business processes; inventory and purchasing. You will continue to interact with both the source systems (MongoDB and MySQL), and the destination system (the Northwind_DW2 data warehouse) from a remote client running Python (Jupyter Notebooks). \n",
    "\n",
    "Just as in Lab 3, you will fetch data into Pandas DataFrames, perform all the necessary transformations in-memory on the client, and then push the newly transformed DataFrame to the RDBMS data warehouse using a Pandas function that will create the table and fill it with data with a single operation.\n",
    "\n",
    "### Prerequisites:\n",
    "#### Import the Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8b95ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "import pymongo\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c629e4",
   "metadata": {},
   "source": [
    "#### Declare & Assign Connection Variables for the MongoDB Server, the MySQL Server & Databases with which You'll be Working "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28890801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Connection String: mongodb://localhost:27017/\n",
      "Atlas Connection String: mongodb+srv://m001-student:m001-mongodb-basics@sandbox.zibbf.mongodb.net\n"
     ]
    }
   ],
   "source": [
    "mysql_uid = \"jtupitza\"\n",
    "mysql_pwd = \"Passw0rd123\"\n",
    "\n",
    "atlas_cluster_name = \"sandbox.zibbf\"\n",
    "atlas_user_name = \"m001-student\"\n",
    "atlas_password = \"m001-mongodb-basics\"\n",
    "\n",
    "conn_str = {\"local\" : f\"mongodb://localhost:27017/\",\n",
    "    \"atlas\" : f\"mongodb+srv://{atlas_user_name}:{atlas_password}@{atlas_cluster_name}.mongodb.net\"\n",
    "}\n",
    "\n",
    "src_dbname = \"northwind_purchasing\"\n",
    "dst_dbname = \"northwind_dw2\"\n",
    "\n",
    "print(f\"Local Connection String: {conn_str['local']}\")\n",
    "print(f\"Atlas Connection String: {conn_str['atlas']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21928a06",
   "metadata": {},
   "source": [
    "#### Define Functions for Getting Data From and Setting Data Into Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eabb5f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql_dataframe(user_id, pwd, db_name, sql_query):\n",
    "    '''Create a connection to the MySQL database'''\n",
    "    conn_str = f\"mysql+pymysql://{user_id}:{pwd}@localhost/{db_name}\"\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    \n",
    "    '''Invoke the pd.read_sql() function to query the database, and fill a Pandas DataFrame.'''\n",
    "    conn = sqlEngine.connect()\n",
    "    dframe = pd.read_sql(sql_query, conn);\n",
    "    conn.close()\n",
    "    \n",
    "    return dframe\n",
    "\n",
    "\n",
    "def get_mongo_dataframe(connect_str, db_name, collection, query):\n",
    "    '''Create a connection to MongoDB'''\n",
    "    client = pymongo.MongoClient(connect_str)\n",
    "    \n",
    "    '''Query MongoDB, and fill a python list with documents to create a DataFrame'''\n",
    "    db = client[db_name]\n",
    "    dframe = pd.DataFrame(list(db[collection].find(query)))\n",
    "    dframe.drop(['_id'], axis=1, inplace=True)\n",
    "    client.close()\n",
    "    return dframe\n",
    "\n",
    "\n",
    "def set_dataframe(user_id, pwd, db_name, df, table_name, pk_column, db_operation):\n",
    "    '''Create a connection to the MySQL database'''\n",
    "    conn_str = f\"mysql+pymysql://{user_id}:{pwd}@localhost/{db_name}\"\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    connection = sqlEngine.connect()\n",
    "    \n",
    "    '''Invoke the Pandas DataFrame .to_sql( ) function to either create, or append to, a table'''\n",
    "    if db_operation == \"insert\":\n",
    "        df.to_sql(table_name, con=connection, index=False, if_exists='replace')\n",
    "        sqlEngine.execute(f\"ALTER TABLE {table_name} ADD PRIMARY KEY ({pk_column});\")\n",
    "            \n",
    "    elif db_operation == \"update\":\n",
    "        df.to_sql(table_name, con=connection, index=False, if_exists='append')\n",
    "    \n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7a3a43",
   "metadata": {},
   "source": [
    "#### Populate MongoDB with Source Data\n",
    "You only need to run this cell once; however, the operation is *idempotent*.  In other words, it can be run multiple times without changing the end result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9772c78a",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationFailure",
     "evalue": "bad auth : authentication failed, full error: {'ok': 0, 'errmsg': 'bad auth : authentication failed', 'code': 8000, 'codeName': 'AtlasError'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationFailure\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 14\u001b[0m\n\u001b[1;32m      7\u001b[0m json_files \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuppliers\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorthwind_suppliers.json\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvoices\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorthwind_invoices.json\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpurchase_orders\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorthwind_purchase_orders.json\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minventory_transactions\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorthwind_inventory_transactions.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     11\u001b[0m              }\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m json_files:\n\u001b[0;32m---> 14\u001b[0m     db\u001b[38;5;241m.\u001b[39mdrop_collection(file)\n\u001b[1;32m     15\u001b[0m     json_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, json_files[file])\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(json_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m openfile:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pymongo/_csot.py:108\u001b[0m, in \u001b[0;36mapply.<locals>.csot_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _TimeoutContext(timeout):\n\u001b[1;32m    107\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pymongo/database.py:1245\u001b[0m, in \u001b[0;36mDatabase.drop_collection\u001b[0;34m(self, name_or_collection, session, comment, encrypted_fields)\u001b[0m\n\u001b[1;32m   1238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drop_helper(\n\u001b[1;32m   1239\u001b[0m         _esc_coll_name(encrypted_fields, name), session\u001b[38;5;241m=\u001b[39msession, comment\u001b[38;5;241m=\u001b[39mcomment\n\u001b[1;32m   1240\u001b[0m     )\n\u001b[1;32m   1241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drop_helper(\n\u001b[1;32m   1242\u001b[0m         _ecoc_coll_name(encrypted_fields, name), session\u001b[38;5;241m=\u001b[39msession, comment\u001b[38;5;241m=\u001b[39mcomment\n\u001b[1;32m   1243\u001b[0m     )\n\u001b[0;32m-> 1245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drop_helper(name, session, comment)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pymongo/database.py:1158\u001b[0m, in \u001b[0;36mDatabase._drop_helper\u001b[0;34m(self, name, session, comment)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m comment \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1156\u001b[0m     command[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomment\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m comment\n\u001b[0;32m-> 1158\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__client\u001b[38;5;241m.\u001b[39m_conn_for_writes(session) \u001b[38;5;28;01mas\u001b[39;00m connection:\n\u001b[1;32m   1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_command(\n\u001b[1;32m   1160\u001b[0m         connection,\n\u001b[1;32m   1161\u001b[0m         command,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1165\u001b[0m         session\u001b[38;5;241m=\u001b[39msession,\n\u001b[1;32m   1166\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pymongo/mongo_client.py:1246\u001b[0m, in \u001b[0;36mMongoClient._checkout\u001b[0;34m(self, server, session)\u001b[0m\n\u001b[1;32m   1244\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m session\u001b[38;5;241m.\u001b[39m_pinned_connection\n\u001b[1;32m   1245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 1246\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m server\u001b[38;5;241m.\u001b[39mcheckout(handler\u001b[38;5;241m=\u001b[39merr_handler) \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;66;03m# Pin this session to the selected server or connection.\u001b[39;00m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1249\u001b[0m         in_txn\n\u001b[1;32m   1250\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m session\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         )\n\u001b[1;32m   1256\u001b[0m     ):\n\u001b[1;32m   1257\u001b[0m         session\u001b[38;5;241m.\u001b[39m_pin(server, conn)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pymongo/pool.py:1598\u001b[0m, in \u001b[0;36mPool.checkout\u001b[0;34m(self, handler)\u001b[0m\n\u001b[1;32m   1595\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m listeners \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1596\u001b[0m     listeners\u001b[38;5;241m.\u001b[39mpublish_connection_check_out_started(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddress)\n\u001b[0;32m-> 1598\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_conn(handler\u001b[38;5;241m=\u001b[39mhandler)\n\u001b[1;32m   1600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menabled_for_cmap:\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m listeners \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pymongo/pool.py:1714\u001b[0m, in \u001b[0;36mPool._get_conn\u001b[0;34m(self, handler)\u001b[0m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# We need to create a new connection\u001b[39;00m\n\u001b[1;32m   1713\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1714\u001b[0m         conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect(handler\u001b[38;5;241m=\u001b[39mhandler)\n\u001b[1;32m   1715\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1716\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_connecting_cond:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pymongo/pool.py:1568\u001b[0m, in \u001b[0;36mPool.connect\u001b[0;34m(self, handler)\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m handler:\n\u001b[1;32m   1566\u001b[0m         handler\u001b[38;5;241m.\u001b[39mcontribute_socket(conn, completed_handshake\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1568\u001b[0m     conn\u001b[38;5;241m.\u001b[39mauthenticate()\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[1;32m   1570\u001b[0m     conn\u001b[38;5;241m.\u001b[39mclose_conn(ConnectionClosedReason\u001b[38;5;241m.\u001b[39mERROR)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pymongo/pool.py:1042\u001b[0m, in \u001b[0;36mConnection.authenticate\u001b[0;34m(self, reauthenticate)\u001b[0m\n\u001b[1;32m   1040\u001b[0m creds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopts\u001b[38;5;241m.\u001b[39m_credentials\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m creds:\n\u001b[0;32m-> 1042\u001b[0m     auth\u001b[38;5;241m.\u001b[39mauthenticate(creds, \u001b[38;5;28mself\u001b[39m, reauthenticate\u001b[38;5;241m=\u001b[39mreauthenticate)\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menabled_for_cmap:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pymongo/auth.py:616\u001b[0m, in \u001b[0;36mauthenticate\u001b[0;34m(credentials, conn, reauthenticate)\u001b[0m\n\u001b[1;32m    614\u001b[0m     _authenticate_oidc(credentials, conn, reauthenticate)\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 616\u001b[0m     auth_func(credentials, conn)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pymongo/auth.py:521\u001b[0m, in \u001b[0;36m_authenticate_default\u001b[0;34m(credentials, conn)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _authenticate_scram(credentials, conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSCRAM-SHA-256\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 521\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _authenticate_scram(credentials, conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSCRAM-SHA-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _authenticate_scram(credentials, conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSCRAM-SHA-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pymongo/auth.py:289\u001b[0m, in \u001b[0;36m_authenticate_scram\u001b[0;34m(credentials, conn, mechanism)\u001b[0m\n\u001b[1;32m    280\u001b[0m server_sig \u001b[38;5;241m=\u001b[39m standard_b64encode(_hmac(server_key, auth_msg, digestmod)\u001b[38;5;241m.\u001b[39mdigest())\n\u001b[1;32m    282\u001b[0m cmd \u001b[38;5;241m=\u001b[39m SON(\n\u001b[1;32m    283\u001b[0m     [\n\u001b[1;32m    284\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaslContinue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m     ]\n\u001b[1;32m    288\u001b[0m )\n\u001b[0;32m--> 289\u001b[0m res \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mcommand(source, cmd)\n\u001b[1;32m    291\u001b[0m parsed \u001b[38;5;241m=\u001b[39m _parse_scram_response(res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpayload\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m hmac\u001b[38;5;241m.\u001b[39mcompare_digest(parsed[\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m\"\u001b[39m], server_sig):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pymongo/helpers.py:315\u001b[0m, in \u001b[0;36m_handle_reauth.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymongo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Connection\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OperationFailure \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m no_reauth:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pymongo/pool.py:932\u001b[0m, in \u001b[0;36mConnection.command\u001b[0;34m(self, dbname, spec, read_preference, codec_options, check, allowable_errors, read_concern, write_concern, parse_write_concern_error, collation, session, client, retryable_write, publish_events, user_fields, exhaust_allowed)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_not_writable(unacknowledged)\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m command(\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    934\u001b[0m         dbname,\n\u001b[1;32m    935\u001b[0m         spec,\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_mongos,\n\u001b[1;32m    937\u001b[0m         read_preference,\n\u001b[1;32m    938\u001b[0m         codec_options,\n\u001b[1;32m    939\u001b[0m         session,\n\u001b[1;32m    940\u001b[0m         client,\n\u001b[1;32m    941\u001b[0m         check,\n\u001b[1;32m    942\u001b[0m         allowable_errors,\n\u001b[1;32m    943\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddress,\n\u001b[1;32m    944\u001b[0m         listeners,\n\u001b[1;32m    945\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_bson_size,\n\u001b[1;32m    946\u001b[0m         read_concern,\n\u001b[1;32m    947\u001b[0m         parse_write_concern_error\u001b[38;5;241m=\u001b[39mparse_write_concern_error,\n\u001b[1;32m    948\u001b[0m         collation\u001b[38;5;241m=\u001b[39mcollation,\n\u001b[1;32m    949\u001b[0m         compression_ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression_context,\n\u001b[1;32m    950\u001b[0m         use_op_msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mop_msg_enabled,\n\u001b[1;32m    951\u001b[0m         unacknowledged\u001b[38;5;241m=\u001b[39munacknowledged,\n\u001b[1;32m    952\u001b[0m         user_fields\u001b[38;5;241m=\u001b[39muser_fields,\n\u001b[1;32m    953\u001b[0m         exhaust_allowed\u001b[38;5;241m=\u001b[39mexhaust_allowed,\n\u001b[1;32m    954\u001b[0m         write_concern\u001b[38;5;241m=\u001b[39mwrite_concern,\n\u001b[1;32m    955\u001b[0m     )\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (OperationFailure, NotPrimaryError):\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pymongo/network.py:191\u001b[0m, in \u001b[0;36mcommand\u001b[0;34m(conn, dbname, spec, is_mongos, read_preference, codec_options, session, client, check, allowable_errors, address, listeners, max_bson_size, read_concern, parse_write_concern_error, collation, compression_ctx, use_op_msg, unacknowledged, user_fields, exhaust_allowed, write_concern)\u001b[0m\n\u001b[1;32m    189\u001b[0m             client\u001b[38;5;241m.\u001b[39m_process_response(response_doc, session)\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m check:\n\u001b[0;32m--> 191\u001b[0m             helpers\u001b[38;5;241m.\u001b[39m_check_command_response(\n\u001b[1;32m    192\u001b[0m                 response_doc,\n\u001b[1;32m    193\u001b[0m                 conn\u001b[38;5;241m.\u001b[39mmax_wire_version,\n\u001b[1;32m    194\u001b[0m                 allowable_errors,\n\u001b[1;32m    195\u001b[0m                 parse_write_concern_error\u001b[38;5;241m=\u001b[39mparse_write_concern_error,\n\u001b[1;32m    196\u001b[0m             )\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m publish:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pymongo/helpers.py:223\u001b[0m, in \u001b[0;36m_check_command_response\u001b[0;34m(response, max_wire_version, allowable_errors, parse_write_concern_error)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m43\u001b[39m:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CursorNotFound(errmsg, code, response, max_wire_version)\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OperationFailure(errmsg, code, response, max_wire_version)\n",
      "\u001b[0;31mOperationFailure\u001b[0m: bad auth : authentication failed, full error: {'ok': 0, 'errmsg': 'bad auth : authentication failed', 'code': 8000, 'codeName': 'AtlasError'}"
     ]
    }
   ],
   "source": [
    "client = pymongo.MongoClient(conn_str[\"atlas\"])\n",
    "db = client[src_dbname]\n",
    "\n",
    "# Gets the path of the Current Working Directory for this Notebook, and then Appends the 'data' directory.\n",
    "data_dir = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "json_files = {\"suppliers\" : 'northwind_suppliers.json',\n",
    "              \"invoices\" : 'northwind_invoices.json',\n",
    "              \"purchase_orders\" : 'northwind_purchase_orders.json',\n",
    "              \"inventory_transactions\" : 'northwind_inventory_transactions.json'\n",
    "             }\n",
    "\n",
    "for file in json_files:\n",
    "    db.drop_collection(file)\n",
    "    json_file = os.path.join(data_dir, json_files[file])\n",
    "    with open(json_file, 'r') as openfile:\n",
    "        json_object = json.load(openfile)\n",
    "        file = db[file]\n",
    "        result = file.insert_many(json_object)\n",
    "        #print(f\"{file} was successfully loaded.\")\n",
    "\n",
    "        \n",
    "client.close()        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41747a78",
   "metadata": {},
   "source": [
    "### 1.0. Create and Populate the New Dimension Tables\n",
    "#### 1.1. Extract Data from the Source MongoDB Collections Into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4957b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {}\n",
    "collection = \"suppliers\"\n",
    "\n",
    "df_suppliers = get_mongo_dataframe(conn_str['atlas'], src_dbname, collection, query)\n",
    "df_suppliers.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d79acc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Extract data from the \"Invoices\" collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10272202",
   "metadata": {},
   "source": [
    "#### 1.2. Perform Any Necessary Transformations to the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84ba2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_suppliers.rename(columns={\"id\":\"supplier_key\"}, inplace=True)\n",
    "df_suppliers.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb8e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perform any required transformations to the \"Invoices\" dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd16f44",
   "metadata": {},
   "source": [
    "#### 1.3. Load the Transformed DataFrames into the New Data Warehouse by Creating New Tables\n",
    "\n",
    "Here we will call our **set_dataframe( )** function to create each dimension table. This function expects a number of parameters including the usual connection information (e.g., user_id, password, MySQL server name and database), the *table_name* we need to assign to the table, the *pandas DataFrame* we crafted to define & populate the table, the *name* we need to assign to the *primary_key* column, and finally, the database operation (insert or update). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5d4291",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = df_suppliers\n",
    "table_name = 'dim_suppliers'\n",
    "primary_key = 'supplier_key'\n",
    "db_operation = \"insert\"\n",
    "\n",
    "set_dataframe(mysql_uid, mysql_pwd, dst_dbname, dataframe, table_name, primary_key, db_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ab37bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Upload the \"Invoices\" dataframe to create the new \"dim_invoices\" dimension table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2411d8e",
   "metadata": {},
   "source": [
    "#### 1.4. Validate that the New Dimension Tables were Created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4ed928",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_suppliers = \"SELECT * FROM northwind_dw2.dim_suppliers;\"\n",
    "df_dim_suppliers = get_sql_dataframe(mysql_uid, mysql_pwd, dst_dbname, sql_suppliers)\n",
    "df_dim_suppliers.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e5737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Validate the new \"dim_invoices\" table in the northwind_dw2 data warehouse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b015eb8e",
   "metadata": {},
   "source": [
    "### 2.0. Create and Populate the New Fact Tables\n",
    "#### 2.1. Extract Data from the Source MongoDB Collections Into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d73c1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {} # Select all elements (columns), and all documents (rows).\n",
    "\n",
    "collection = \"purchase_orders\"\n",
    "\n",
    "df_pos = get_mongo_dataframe(conn_str['atlas'], src_dbname, collection, query)\n",
    "df_pos.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c5e338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract data for your new \"Inventory Transactions\" Fact Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53ef721",
   "metadata": {},
   "source": [
    "#### 2.2. Perform Any Necessary Transformations to the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977189aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name_map = {\"purchase_order_id\" : \"purchase_order_key\",\n",
    "                   \"supplier_id\" : \"supplier_key\",\n",
    "                   \"purchase_order_detail_id\" : \"purchase_order_detail_key\",\n",
    "                   \"product_id\" : \"product_key\",\n",
    "                   \"inventory_id\" : \"inventory_key\"\n",
    "                  }\n",
    "\n",
    "df_pos.rename(columns=column_name_map, inplace=True)\n",
    "df_pos.insert(0, \"fact_purchase_order_key\", range(1, df_pos.shape[0]+1))\n",
    "df_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5312f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perform any required transformations to the inventory transactions dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7a226d",
   "metadata": {},
   "source": [
    "#### 2.3. Load Newly Transformed MongoDB Data into the Northwind_DW2 Data Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfe8e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = df_pos\n",
    "table_name = 'fact_purchase_orders'\n",
    "primary_key = 'Fact_purchase_order_key'\n",
    "db_operation = \"insert\"\n",
    "\n",
    "set_dataframe(mysql_uid, mysql_pwd, dst_dbname, dataframe, table_name, primary_key, db_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf15520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Upload the \"Inventory Transaction\" dataframe to create the new \"fact_inventory_transactions\" fact table. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c58a3d2",
   "metadata": {},
   "source": [
    "#### 2.4. Validate that the New Fact Tables were Created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962a5636",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_purchase_orders = \"SELECT * FROM northwind_dw2.fact_purchase_orders;\"\n",
    "df_fact_purchase_orders = get_sql_dataframe(mysql_uid, mysql_pwd, dst_dbname, sql_purchase_orders)\n",
    "df_fact_purchase_orders.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48a84cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Validate the correctness of the new \"Inventory Transactions\" fact table."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
